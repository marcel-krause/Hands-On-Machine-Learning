{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning Model Parameters via a Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from scipy.stats import reciprocal\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5160, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3870, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5160,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3870,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_valid = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the randomized search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs = {\n",
    "    'n_hidden': [0, 1, 2, 3],\n",
    "    'n_neurons': np.arange(1, 100),\n",
    "    'learning_rate': reciprocal(3e-4, 3e-2)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model by iterating over the randomized parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "242/242 [==============================] - ETA: 0s - loss: 3.1694 - 0s 964us/step - loss: 2.8008 - val_loss: 0.5407\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 545us/step - loss: 4.1743 - val_loss: 1.1278\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 546us/step - loss: 22.0868 - val_loss: 3.0870\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 534us/step - loss: 79.5358 - val_loss: 24.0339\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 517us/step - loss: 93.1564 - val_loss: 230.9524\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 526us/step - loss: 16568.6797 - val_loss: 955.9703\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 542us/step - loss: 65031.1608 - val_loss: 6689.5122\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 526us/step - loss: 183939.6986 - val_loss: 52198.2070\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 521us/step - loss: 4251488.3687 - val_loss: 327414.4062\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 521us/step - loss: 31799156.5665 - val_loss: 2290235.2500\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 526us/step - loss: 56299588.6776 - val_loss: 18809480.0000\n",
      "121/121 [==============================] - 0s 307us/step - loss: 1140996480.0000\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 857us/step - loss: 3.1734 - val_loss: 0.7116\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 550us/step - loss: 0.6558 - val_loss: 0.5880\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.5791 - val_loss: 0.5648\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 550us/step - loss: 0.5236 - val_loss: 0.5494\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.5447 - val_loss: 0.5518\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 550us/step - loss: 0.5360 - val_loss: 0.5403\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 550us/step - loss: 0.5436 - val_loss: 0.5404\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.4876 - val_loss: 0.5493\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 555us/step - loss: 0.5244 - val_loss: 0.5439\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.5175 - val_loss: 0.5424\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.5447 - val_loss: 0.5353\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.5246 - val_loss: 0.5438\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.5247 - val_loss: 0.5429\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.5236 - val_loss: 0.5384\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.5098 - val_loss: 0.6098\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.5370 - val_loss: 0.5357\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.5150 - val_loss: 0.5571\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.5152 - val_loss: 0.6285\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.5082 - val_loss: 0.6065\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.5388 - val_loss: 0.5368\n",
      "121/121 [==============================] - 0s 299us/step - loss: 0.4940\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 852us/step - loss: 3.9403 - val_loss: 0.5865\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.5511 - val_loss: 0.5663\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.5176 - val_loss: 0.5534\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.5259 - val_loss: 0.5481\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.5260 - val_loss: 0.5630\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.5140 - val_loss: 0.5428\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.4905 - val_loss: 0.5407\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.4946 - val_loss: 0.5394\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 541us/step - loss: 0.5012 - val_loss: 0.5375\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.4965 - val_loss: 0.5604\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.5298 - val_loss: 0.5352\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.5013 - val_loss: 0.5538\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.4943 - val_loss: 0.5361\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.4996 - val_loss: 0.5470\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.5041 - val_loss: 0.5415\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.4990 - val_loss: 0.5349\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.5052 - val_loss: 0.5435\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.4876 - val_loss: 0.6757\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.5280 - val_loss: 0.5390\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.5027 - val_loss: 0.5466\n",
      "121/121 [==============================] - 0s 299us/step - loss: 0.5349\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 919us/step - loss: 2.1079 - val_loss: 0.6995\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.7031 - val_loss: 4.6212\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 571us/step - loss: 1.0085 - val_loss: 0.5335\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 567us/step - loss: 0.5118 - val_loss: 0.4873\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 563us/step - loss: 0.4575 - val_loss: 0.4725\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 584us/step - loss: 0.4845 - val_loss: 0.4535\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.4459 - val_loss: 0.4421\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 600us/step - loss: 0.4249 - val_loss: 0.4359\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 563us/step - loss: 0.4032 - val_loss: 0.4280\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 563us/step - loss: 0.3912 - val_loss: 0.4243\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 559us/step - loss: 0.3908 - val_loss: 0.4130\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 567us/step - loss: 0.3859 - val_loss: 0.4083\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 555us/step - loss: 0.4012 - val_loss: 0.4055\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 555us/step - loss: 0.3663 - val_loss: 0.4014\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 584us/step - loss: 0.3805 - val_loss: 0.3968\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 559us/step - loss: 0.3768 - val_loss: 0.3948\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3900 - val_loss: 0.3899\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3892 - val_loss: 0.3896\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 567us/step - loss: 0.3747 - val_loss: 0.3863\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 583us/step - loss: 0.3566 - val_loss: 0.3856\n",
      "121/121 [==============================] - 0s 299us/step - loss: 0.3579\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 919us/step - loss: 1.7667 - val_loss: 0.7742\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.6660 - val_loss: 0.5609\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 546us/step - loss: 0.5659 - val_loss: 0.5306\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 575us/step - loss: 0.4873 - val_loss: 0.5262\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 563us/step - loss: 0.4758 - val_loss: 0.4949\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 555us/step - loss: 0.5028 - val_loss: 0.4732\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 637us/step - loss: 0.4668 - val_loss: 0.4663\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 567us/step - loss: 0.4524 - val_loss: 0.4618\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 546us/step - loss: 0.4428 - val_loss: 0.4591\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 546us/step - loss: 0.4217 - val_loss: 0.4595\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.4384 - val_loss: 0.4484\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 619us/step - loss: 0.4079 - val_loss: 0.4476\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.4037 - val_loss: 0.4396\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 550us/step - loss: 0.4173 - val_loss: 0.4358\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.4123 - val_loss: 0.4315\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 543us/step - loss: 0.3927 - val_loss: 0.4319\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3971 - val_loss: 0.4358\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 558us/step - loss: 0.3992 - val_loss: 0.4227\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 549us/step - loss: 0.3931 - val_loss: 0.4196\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 553us/step - loss: 0.4157 - val_loss: 0.4210\n",
      "121/121 [==============================] - 0s 299us/step - loss: 0.3864\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 835us/step - loss: 1.7597 - val_loss: 0.6144\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 599us/step - loss: 0.5540 - val_loss: 0.5506\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 567us/step - loss: 0.4993 - val_loss: 0.5139\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 561us/step - loss: 0.4559 - val_loss: 0.5141\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 551us/step - loss: 0.4592 - val_loss: 0.4856\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 571us/step - loss: 0.4479 - val_loss: 0.4801\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 571us/step - loss: 0.4237 - val_loss: 0.4716\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 575us/step - loss: 0.4316 - val_loss: 0.4658\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4314 - val_loss: 0.4611\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 555us/step - loss: 0.4309 - val_loss: 0.4596\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 571us/step - loss: 0.4171 - val_loss: 0.4561\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 555us/step - loss: 0.3937 - val_loss: 0.4516\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 559us/step - loss: 0.3962 - val_loss: 0.4498\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 563us/step - loss: 0.4040 - val_loss: 0.4453\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 563us/step - loss: 0.3935 - val_loss: 0.4410\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 579us/step - loss: 0.3963 - val_loss: 0.4514\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 571us/step - loss: 0.4172 - val_loss: 0.4394\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 571us/step - loss: 0.3945 - val_loss: 0.4454\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.3996 - val_loss: 0.4332\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 561us/step - loss: 0.3977 - val_loss: 0.4287\n",
      "121/121 [==============================] - 0s 308us/step - loss: 0.4318\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 827us/step - loss: 4.8193 - val_loss: 1.7727\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 535us/step - loss: 1.3681 - val_loss: 0.8458\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 545us/step - loss: 0.7450 - val_loss: 0.6358\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 537us/step - loss: 0.5785 - val_loss: 0.5826\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.5660 - val_loss: 0.5662\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.5477 - val_loss: 0.5593\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.5414 - val_loss: 0.5555\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.5478 - val_loss: 0.5526\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.5247 - val_loss: 0.5504\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.5352 - val_loss: 0.5484\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.5150 - val_loss: 0.5466\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.5206 - val_loss: 0.5450\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.5407 - val_loss: 0.5439\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.5225 - val_loss: 0.5427\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 524us/step - loss: 0.5196 - val_loss: 0.5418\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 524us/step - loss: 0.5317 - val_loss: 0.5410\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.5037 - val_loss: 0.5402\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.5095 - val_loss: 0.5396\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 541us/step - loss: 0.5208 - val_loss: 0.5394\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.5036 - val_loss: 0.5389\n",
      "121/121 [==============================] - 0s 308us/step - loss: 0.5044\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 838us/step - loss: 5.5584 - val_loss: 1.9888\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 513us/step - loss: 1.5847 - val_loss: 0.9828\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.8812 - val_loss: 0.7387\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.6885 - val_loss: 0.6660\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 529us/step - loss: 0.6532 - val_loss: 0.6376\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.6235 - val_loss: 0.6206\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 518us/step - loss: 0.6124 - val_loss: 0.6075\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 520us/step - loss: 0.6105 - val_loss: 0.5979\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.5880 - val_loss: 0.5894\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.5810 - val_loss: 0.5821\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.5617 - val_loss: 0.5759\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.5416 - val_loss: 0.5709\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 529us/step - loss: 0.5929 - val_loss: 0.5663\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.5540 - val_loss: 0.5622\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 541us/step - loss: 0.5637 - val_loss: 0.5589\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 520us/step - loss: 0.5322 - val_loss: 0.5561\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.5270 - val_loss: 0.5539\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.5459 - val_loss: 0.5510\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.5275 - val_loss: 0.5497\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.5379 - val_loss: 0.5489\n",
      "121/121 [==============================] - 0s 291us/step - loss: 0.5059\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 841us/step - loss: 4.4218 - val_loss: 1.8108\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 514us/step - loss: 1.4442 - val_loss: 0.9127\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 516us/step - loss: 0.7756 - val_loss: 0.7038\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.6621 - val_loss: 0.6467\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.5991 - val_loss: 0.6248\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.5886 - val_loss: 0.6126\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 529us/step - loss: 0.5845 - val_loss: 0.6030\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.5642 - val_loss: 0.5942\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.5424 - val_loss: 0.5872\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.5525 - val_loss: 0.5812\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.5380 - val_loss: 0.5758\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.5514 - val_loss: 0.5712\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.5352 - val_loss: 0.5671\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.5239 - val_loss: 0.5634\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.5336 - val_loss: 0.5605\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.5442 - val_loss: 0.5576\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.5340 - val_loss: 0.5550\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.5068 - val_loss: 0.5526\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.5325 - val_loss: 0.5510\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.4949 - val_loss: 0.5494\n",
      "121/121 [==============================] - 0s 299us/step - loss: 0.5519\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 940us/step - loss: 1.5374 - val_loss: 1.1817\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 582us/step - loss: 0.9947 - val_loss: 0.5531\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 579us/step - loss: 0.5567 - val_loss: 0.4975\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 580us/step - loss: 0.4747 - val_loss: 0.4721\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 575us/step - loss: 0.4640 - val_loss: 0.4613\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.4507 - val_loss: 0.4483\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 595us/step - loss: 0.4053 - val_loss: 0.4450\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 578us/step - loss: 0.4323 - val_loss: 0.4364\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 549us/step - loss: 0.4077 - val_loss: 0.4317\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 578us/step - loss: 0.4007 - val_loss: 0.4290\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 562us/step - loss: 0.4108 - val_loss: 0.4261\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 619us/step - loss: 0.3872 - val_loss: 0.4177\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3855 - val_loss: 0.4174\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.3943 - val_loss: 0.4154\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 580us/step - loss: 0.3731 - val_loss: 0.4078\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3996 - val_loss: 0.4040\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 597us/step - loss: 0.3735 - val_loss: 0.4034\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 580us/step - loss: 0.3686 - val_loss: 0.4011\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 596us/step - loss: 0.3742 - val_loss: 0.3947\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 570us/step - loss: 0.3599 - val_loss: 0.3941\n",
      "121/121 [==============================] - 0s 308us/step - loss: 0.3642\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 889us/step - loss: 1.6496 - val_loss: 0.6673\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 567us/step - loss: 0.6729 - val_loss: 0.5490\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 563us/step - loss: 0.5211 - val_loss: 0.5174\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 621us/step - loss: 0.4829 - val_loss: 0.4835\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 570us/step - loss: 0.4525 - val_loss: 0.4697\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 592us/step - loss: 0.4521 - val_loss: 0.4531\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 571us/step - loss: 0.4520 - val_loss: 0.4464\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 567us/step - loss: 0.4281 - val_loss: 0.4407\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.4047 - val_loss: 0.4380\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 578us/step - loss: 0.3942 - val_loss: 0.4296\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.4204 - val_loss: 0.4259\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 580us/step - loss: 0.3938 - val_loss: 0.4250\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 575us/step - loss: 0.3855 - val_loss: 0.4184\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.4309 - val_loss: 0.4165\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 554us/step - loss: 0.3760 - val_loss: 0.4096\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 559us/step - loss: 0.4117 - val_loss: 0.4120\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 553us/step - loss: 0.3927 - val_loss: 0.4062\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 554us/step - loss: 0.3851 - val_loss: 0.4023\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 580us/step - loss: 0.3794 - val_loss: 0.4004\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3869 - val_loss: 0.3976\n",
      "121/121 [==============================] - 0s 308us/step - loss: 0.3669\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 912us/step - loss: 1.5173 - val_loss: 0.6066\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.5481 - val_loss: 0.6171\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 586us/step - loss: 0.5462 - val_loss: 0.5016\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 590us/step - loss: 0.4695 - val_loss: 0.4849\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.4284 - val_loss: 0.4667\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 572us/step - loss: 0.4063 - val_loss: 0.4621\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 576us/step - loss: 0.4362 - val_loss: 0.4531\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 583us/step - loss: 0.4036 - val_loss: 0.4421\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.4343 - val_loss: 0.4389\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 571us/step - loss: 0.4032 - val_loss: 0.4361\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 588us/step - loss: 0.3930 - val_loss: 0.4280\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3859 - val_loss: 0.4243\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 570us/step - loss: 0.3824 - val_loss: 0.4205\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 583us/step - loss: 0.3653 - val_loss: 0.4138\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 571us/step - loss: 0.3936 - val_loss: 0.4123\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 590us/step - loss: 0.3869 - val_loss: 0.4058\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 594us/step - loss: 0.3823 - val_loss: 0.4204\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 584us/step - loss: 0.3610 - val_loss: 0.4018\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 583us/step - loss: 0.3548 - val_loss: 0.3958\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 617us/step - loss: 0.3583 - val_loss: 0.3939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 314us/step - loss: 0.3967\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2189 - val_loss: 0.9026\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.7267 - val_loss: 0.5724\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 584us/step - loss: 0.5084 - val_loss: 0.5451\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 563us/step - loss: 0.5387 - val_loss: 0.5404\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.5175 - val_loss: 0.5393\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 537us/step - loss: 0.5303 - val_loss: 0.5384\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.4963 - val_loss: 0.5395\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.5212 - val_loss: 0.5364\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.5091 - val_loss: 0.5381\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.5004 - val_loss: 0.5382\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.4986 - val_loss: 0.5376\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.5134 - val_loss: 0.5371\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.5249 - val_loss: 0.5379\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.5060 - val_loss: 0.5384\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.5074 - val_loss: 0.5380\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.5111 - val_loss: 0.5369\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 555us/step - loss: 0.5242 - val_loss: 0.5364\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 518us/step - loss: 0.5203 - val_loss: 0.5381\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.5101 - val_loss: 0.5375\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.5376 - val_loss: 0.5363\n",
      "121/121 [==============================] - 0s 299us/step - loss: 0.5047\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 810us/step - loss: 5.9492 - val_loss: 1.0097\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.8161 - val_loss: 0.6399\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.6036 - val_loss: 0.5989\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.5647 - val_loss: 0.5801\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.5594 - val_loss: 0.5697\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.5552 - val_loss: 0.5607\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 543us/step - loss: 0.5519 - val_loss: 0.5570\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.5317 - val_loss: 0.5533\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 537us/step - loss: 0.5463 - val_loss: 0.5504\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.5108 - val_loss: 0.5439\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 572us/step - loss: 0.4973 - val_loss: 0.5424\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 567us/step - loss: 0.5360 - val_loss: 0.5427\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 578us/step - loss: 0.5143 - val_loss: 0.5400\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.5264 - val_loss: 0.5397\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 546us/step - loss: 0.5043 - val_loss: 0.5527\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 600us/step - loss: 0.4903 - val_loss: 0.5380\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 550us/step - loss: 0.5149 - val_loss: 0.5440\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.5412 - val_loss: 0.5430\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.5121 - val_loss: 0.5389\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.5236 - val_loss: 0.5373\n",
      "121/121 [==============================] - 0s 311us/step - loss: 0.4907\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 897us/step - loss: 5.4265 - val_loss: 1.0309\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 563us/step - loss: 0.8818 - val_loss: 0.6795\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.6683 - val_loss: 0.6352\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.5762 - val_loss: 0.6121\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.5942 - val_loss: 0.5954\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.5477 - val_loss: 0.5823\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 537us/step - loss: 0.5344 - val_loss: 0.5754\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.5367 - val_loss: 0.5642\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.5196 - val_loss: 0.5607\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 529us/step - loss: 0.5055 - val_loss: 0.5549\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.5057 - val_loss: 0.5605\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.5279 - val_loss: 0.5484\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.4974 - val_loss: 0.5463\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.4946 - val_loss: 0.5439\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.5030 - val_loss: 0.5458\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.5198 - val_loss: 0.5474\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.4963 - val_loss: 0.5397\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.5115 - val_loss: 0.5527\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.5095 - val_loss: 0.5400\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.5027 - val_loss: 0.5695\n",
      "121/121 [==============================] - 0s 283us/step - loss: 0.5462\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 819us/step - loss: 1.5907 - val_loss: 0.5449\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 503us/step - loss: 16.0751 - val_loss: 10.1076\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 514us/step - loss: 2864.1922 - val_loss: 1100.1727\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 519us/step - loss: 34807.5058 - val_loss: 138228.0625\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 517us/step - loss: 26017247.5622 - val_loss: 17063132.0000\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 517us/step - loss: 367326558.4877 - val_loss: 2170212096.0000\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 519us/step - loss: 8856116747.0617 - val_loss: 353972912128.0000\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 514us/step - loss: 30631340452657.5156 - val_loss: 32731352268800.0000\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 512us/step - loss: 29849153407490.1055 - val_loss: 8575053067190272.0000\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 509us/step - loss: 104588481014536528.0000 - val_loss: 681773625279250432.0000\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 512us/step - loss: 159197599253793439744.0000 - val_loss: 83132482083306340352.0000\n",
      "121/121 [==============================] - 0s 291us/step - loss: 6041541182470641156096.0000\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 815us/step - loss: 2.1510 - val_loss: 0.7975\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 503us/step - loss: 879.5284 - val_loss: 28.0574\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 517us/step - loss: 11013.3112 - val_loss: 7699.1445\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 504us/step - loss: 4220450.8954 - val_loss: 1137863.3750\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 510us/step - loss: 545284554.2828 - val_loss: 146647136.0000\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 505us/step - loss: 22620741029.2510 - val_loss: 70243672064.0000\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 510us/step - loss: 573149820692.0165 - val_loss: 6716836020224.0000\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 505us/step - loss: 3595819715815230.0000 - val_loss: 1062652822421504.0000\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 504us/step - loss: 74500880852771184.0000 - val_loss: 162651425111801856.0000\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 499us/step - loss: 135816283122378899456.0000 - val_loss: 130005419239397130240.0000\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 503us/step - loss: 43307126824004474634240.0000 - val_loss: 5304479815655372095488.0000\n",
      "121/121 [==============================] - 0s 290us/step - loss: 2385697178631530348544.0000\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8900 - val_loss: 0.5266\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.7018 - val_loss: 0.5273\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.7693 - val_loss: 0.5558\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 512us/step - loss: 1.0295 - val_loss: 0.6552\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 517us/step - loss: 6.0123 - val_loss: 0.5277\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 512us/step - loss: 5.4450 - val_loss: 0.5486\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 517us/step - loss: 1.1426 - val_loss: 0.5573\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 519us/step - loss: 1.5824 - val_loss: 0.6022\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 516us/step - loss: 1.8091 - val_loss: 0.7838\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 518us/step - loss: 7.2570 - val_loss: 0.6984\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 503us/step - loss: 1.9133 - val_loss: 0.8093\n",
      "121/121 [==============================] - 0s 291us/step - loss: 71.5748\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 846us/step - loss: 2.3945 - val_loss: 0.6481\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 527us/step - loss: 1.1535 - val_loss: 0.6372\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.5743 - val_loss: 0.5520\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.5262 - val_loss: 0.5208\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.4846 - val_loss: 0.5055\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 533us/step - loss: 0.4869 - val_loss: 0.4959\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.4557 - val_loss: 0.4895\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.4854 - val_loss: 0.4837\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.4608 - val_loss: 0.4776\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.4586 - val_loss: 0.4732\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.4574 - val_loss: 0.4726\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 525us/step - loss: 0.4395 - val_loss: 0.4653\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.4317 - val_loss: 0.4607\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.4224 - val_loss: 0.4586\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.4394 - val_loss: 0.4563\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.4467 - val_loss: 0.4544\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.4581 - val_loss: 0.4512\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.4496 - val_loss: 0.4494\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 529us/step - loss: 0.4188 - val_loss: 0.4487\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.4234 - val_loss: 0.4472\n",
      "121/121 [==============================] - 0s 299us/step - loss: 0.4150\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 838us/step - loss: 1.9389 - val_loss: 0.6782\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 541us/step - loss: 0.6546 - val_loss: 0.6008\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.5763 - val_loss: 0.5635\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.5367 - val_loss: 0.5359\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.5068 - val_loss: 0.5101\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.4769 - val_loss: 0.4935\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.4692 - val_loss: 0.4801\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.4762 - val_loss: 0.5199\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.4756 - val_loss: 0.4824\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.4710 - val_loss: 0.4666\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.4720 - val_loss: 0.4712\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.4635 - val_loss: 0.4949\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.4570 - val_loss: 0.4964\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 529us/step - loss: 0.4764 - val_loss: 0.4646\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.4662 - val_loss: 0.4571\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.4649 - val_loss: 0.4560\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.4450 - val_loss: 0.4558\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.4578 - val_loss: 0.4680\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 529us/step - loss: 0.4344 - val_loss: 0.4504\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.4336 - val_loss: 0.4512\n",
      "121/121 [==============================] - 0s 300us/step - loss: 0.4252\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 837us/step - loss: 4.6969 - val_loss: 0.6488\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.5688 - val_loss: 0.5734\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 537us/step - loss: 0.5284 - val_loss: 0.5461\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 537us/step - loss: 0.5020 - val_loss: 0.5215\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 533us/step - loss: 0.4509 - val_loss: 0.5032\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 539us/step - loss: 0.4476 - val_loss: 0.4942\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.4408 - val_loss: 0.5099\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 525us/step - loss: 0.4537 - val_loss: 0.4892\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 525us/step - loss: 0.4483 - val_loss: 0.4787\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.4187 - val_loss: 0.4754\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.4174 - val_loss: 0.4719\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 550us/step - loss: 0.4427 - val_loss: 0.4822\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 546us/step - loss: 0.4361 - val_loss: 0.4676\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.4301 - val_loss: 0.4659\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 524us/step - loss: 0.4453 - val_loss: 0.4658\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.3958 - val_loss: 0.4602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 525us/step - loss: 0.4061 - val_loss: 0.4582\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 550us/step - loss: 0.4001 - val_loss: 0.4554\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.4018 - val_loss: 0.5202\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 541us/step - loss: 0.4535 - val_loss: 0.4664\n",
      "121/121 [==============================] - 0s 287us/step - loss: 0.4666\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 814us/step - loss: 2.2581 - val_loss: 0.7527\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 525us/step - loss: 0.7126 - val_loss: 6.3886\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 505us/step - loss: 33.8813 - val_loss: 236.5398\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 507us/step - loss: 50921.0318 - val_loss: 12254.3760\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 515us/step - loss: 1299770.7080 - val_loss: 683270.8750\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 508us/step - loss: 42125428.1503 - val_loss: 37832564.0000\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 508us/step - loss: 6680285980.2346 - val_loss: 2080660224.0000\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 503us/step - loss: 56858477227.5885 - val_loss: 117125709824.0000\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 515us/step - loss: 5205235245342.5518 - val_loss: 6519087169536.0000\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 501us/step - loss: 178728106753643.4688 - val_loss: 361326740242432.0000\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 501us/step - loss: 23360237243669616.0000 - val_loss: 20103300951048192.0000\n",
      "121/121 [==============================] - 0s 299us/step - loss: 1451234539824218112.0000\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 798us/step - loss: 2.1840 - val_loss: 0.5837\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.6378 - val_loss: 0.6446\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 510us/step - loss: 2.4598 - val_loss: 0.5386\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 505us/step - loss: 1.0476 - val_loss: 0.6595\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 516us/step - loss: 1.6397 - val_loss: 0.8758\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 513us/step - loss: 5.9854 - val_loss: 3.2313\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 508us/step - loss: 326.6805 - val_loss: 10.7466\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 509us/step - loss: 694.2085 - val_loss: 115.4368\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 513us/step - loss: 7890.1015 - val_loss: 3554.0415\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 503us/step - loss: 113252.8241 - val_loss: 4320.5620\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 505us/step - loss: 510750.6151 - val_loss: 52074.0508\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 503us/step - loss: 516604.2934 - val_loss: 63835.2070\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 499us/step - loss: 2497111.5382 - val_loss: 363323.6250\n",
      "121/121 [==============================] - 0s 291us/step - loss: 206038.2500\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 802us/step - loss: 2.1734 - val_loss: 0.5670\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.5330 - val_loss: 0.5439\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.5232 - val_loss: 0.5376\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.5267 - val_loss: 0.5380\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.5081 - val_loss: 0.5380\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.6714 - val_loss: 0.5361\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.5248 - val_loss: 0.5332\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.5149 - val_loss: 1.0277\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 520us/step - loss: 0.6008 - val_loss: 0.5378\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.5802 - val_loss: 0.5393\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.5270 - val_loss: 0.5342\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.6169 - val_loss: 0.5359\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.4877 - val_loss: 0.5349\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.5143 - val_loss: 0.5362\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.5986 - val_loss: 0.5350\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.5139 - val_loss: 0.5357\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.5052 - val_loss: 0.5716\n",
      "121/121 [==============================] - 0s 283us/step - loss: 0.5612\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 802us/step - loss: 5.7260 - val_loss: 4.6816\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 508us/step - loss: 4.3019 - val_loss: 3.5516\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 515us/step - loss: 3.2542 - val_loss: 2.7489\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 517us/step - loss: 2.5413 - val_loss: 2.1753\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 514us/step - loss: 2.0923 - val_loss: 1.7630\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 510us/step - loss: 1.6017 - val_loss: 1.4655\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 514us/step - loss: 1.3878 - val_loss: 1.2500\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 512us/step - loss: 1.1569 - val_loss: 1.0928\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.9830 - val_loss: 0.9775\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.9237 - val_loss: 0.8927\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.8493 - val_loss: 0.8299\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.7859 - val_loss: 0.7829\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.7463 - val_loss: 0.7475\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.7349 - val_loss: 0.7207\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.7109 - val_loss: 0.7001\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 529us/step - loss: 0.6945 - val_loss: 0.6841\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.6535 - val_loss: 0.6714\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.6618 - val_loss: 0.6613\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.6193 - val_loss: 0.6531\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.6566 - val_loss: 0.6463\n",
      "121/121 [==============================] - 0s 291us/step - loss: 0.6285\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 857us/step - loss: 7.0318 - val_loss: 5.3716\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 539us/step - loss: 4.8704 - val_loss: 4.0290\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 569us/step - loss: 3.7454 - val_loss: 3.0851\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 557us/step - loss: 2.8087 - val_loss: 2.4157\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 538us/step - loss: 2.1453 - val_loss: 1.9369\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 524us/step - loss: 1.7815 - val_loss: 1.5928\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 500us/step - loss: 1.4520 - val_loss: 1.3439\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 468us/step - loss: 1.3001 - val_loss: 1.1630\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 518us/step - loss: 1.0453 - val_loss: 1.0307\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 458us/step - loss: 0.9454 - val_loss: 0.9335\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.8337 - val_loss: 0.8617\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.8164 - val_loss: 0.8083\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.6975 - val_loss: 0.7685\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.7366 - val_loss: 0.7386\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 525us/step - loss: 0.6480 - val_loss: 0.7160\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.6616 - val_loss: 0.6987\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.6569 - val_loss: 0.6852\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 543us/step - loss: 0.6382 - val_loss: 0.6748\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.6229 - val_loss: 0.6664\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.6063 - val_loss: 0.6595\n",
      "121/121 [==============================] - 0s 299us/step - loss: 0.5983\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 836us/step - loss: 6.0014 - val_loss: 5.1598\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 534us/step - loss: 4.7947 - val_loss: 4.0049\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 523us/step - loss: 3.8071 - val_loss: 3.1800\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 516us/step - loss: 3.0173 - val_loss: 2.5811\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 527us/step - loss: 2.4352 - val_loss: 2.1446\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 521us/step - loss: 2.1099 - val_loss: 1.8221\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 533us/step - loss: 1.7389 - val_loss: 1.5804\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 523us/step - loss: 1.5020 - val_loss: 1.4004\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 519us/step - loss: 1.3292 - val_loss: 1.2643\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 523us/step - loss: 1.1773 - val_loss: 1.1613\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 516us/step - loss: 1.1715 - val_loss: 1.0828\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 515us/step - loss: 1.0508 - val_loss: 1.0214\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 521us/step - loss: 1.0331 - val_loss: 0.9731\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.9237 - val_loss: 0.9353\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.9390 - val_loss: 0.9044\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.8872 - val_loss: 0.8796\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.8433 - val_loss: 0.8592\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.8502 - val_loss: 0.8415\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.8117 - val_loss: 0.8268\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.7889 - val_loss: 0.8138\n",
      "121/121 [==============================] - 0s 299us/step - loss: 0.8454\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 839us/step - loss: 2.7599 - val_loss: 0.6855\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 529us/step - loss: 3.3496 - val_loss: 0.8026\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 537us/step - loss: 115.7031 - val_loss: 4.9648\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 545us/step - loss: 9.9404 - val_loss: 63.2632\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 534us/step - loss: 3717.7948 - val_loss: 374.1335\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 534us/step - loss: 25614.7157 - val_loss: 3553.0413\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 526us/step - loss: 225519.0798 - val_loss: 35075.1133\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 550us/step - loss: 104631.0209 - val_loss: 581786.1250\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 546us/step - loss: 38632225.6944 - val_loss: 3240006.0000\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 530us/step - loss: 37354305.9882 - val_loss: 41601220.0000\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 518us/step - loss: 60367785.1811 - val_loss: 512935232.0000\n",
      "121/121 [==============================] - 0s 287us/step - loss: 22289803264.0000\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 825us/step - loss: 2.8065 - val_loss: 0.6756\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.6556 - val_loss: 0.5921\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 529us/step - loss: 0.5665 - val_loss: 0.5633\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.5550 - val_loss: 0.5575\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.5275 - val_loss: 0.5444\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 520us/step - loss: 0.5304 - val_loss: 0.6093\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.5490 - val_loss: 0.5552\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.5465 - val_loss: 0.5379\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 563us/step - loss: 0.5066 - val_loss: 0.6079\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 572us/step - loss: 0.5285 - val_loss: 0.5376\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.5478 - val_loss: 0.5397\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.5631 - val_loss: 0.5336\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.5793 - val_loss: 0.5603\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.5267 - val_loss: 0.5364\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.5619 - val_loss: 0.5342\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.5149 - val_loss: 0.5809\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.5367 - val_loss: 0.5369\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.5692 - val_loss: 0.5397\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.5383 - val_loss: 0.5361\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.5087 - val_loss: 0.6980\n",
      "121/121 [==============================] - 0s 299us/step - loss: 0.6529\n",
      "Epoch 1/20\n",
      "242/242 [==============================] - 0s 812us/step - loss: 2.9258 - val_loss: 0.6904\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.6463 - val_loss: 0.5921\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.5494 - val_loss: 0.5620\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.5389 - val_loss: 0.5485\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.4889 - val_loss: 0.5449\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.5186 - val_loss: 0.5380\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 0s 567us/step - loss: 0.5030 - val_loss: 0.5515\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.4962 - val_loss: 0.5672\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 0s 547us/step - loss: 0.5113 - val_loss: 0.6714\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.5609 - val_loss: 0.5381\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.4829 - val_loss: 0.5487\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.4944 - val_loss: 0.5352\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.5083 - val_loss: 0.5636\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.4968 - val_loss: 0.5355\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 517us/step - loss: 0.4951 - val_loss: 0.7153\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.5461 - val_loss: 0.5356\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.4796 - val_loss: 0.6892\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.5503 - val_loss: 0.5354\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.4886 - val_loss: 0.6902\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 0s 520us/step - loss: 0.5380 - val_loss: 0.5462\n",
      "121/121 [==============================] - 0s 291us/step - loss: 0.5415\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x0000021FB8BC20A0>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-9a9321f3806f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrnd_search_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_distribs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m rnd_search_cv.fit(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    759\u001b[0m             \u001b[1;31m# we clone again after setting params in case some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;31m# of the params are estimators as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0m\u001b[0;32m    762\u001b[0m                 **self.best_params_))\n\u001b[0;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mparam2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparam1\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mparam2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0m\u001b[0;32m     97\u001b[0m                                \u001b[1;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                                (estimator, name))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x0000021FB8BC20A0>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Get the parameter set that performed best and its score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.005679089392533315, 'n_hidden': 2, 'n_neurons': 73}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.37595300873120624"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain the model with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 760us/step - loss: 1.5837 - root_mean_squared_error: 1.2339 - val_loss: 0.5966 - val_root_mean_squared_error: 0.7724\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 532us/step - loss: 0.5232 - root_mean_squared_error: 0.7231 - val_loss: 0.5169 - val_root_mean_squared_error: 0.7189\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 539us/step - loss: 0.4933 - root_mean_squared_error: 0.7022 - val_loss: 0.6156 - val_root_mean_squared_error: 0.7846\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 548us/step - loss: 0.4570 - root_mean_squared_error: 0.6760 - val_loss: 0.4642 - val_root_mean_squared_error: 0.6813\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 534us/step - loss: 0.4348 - root_mean_squared_error: 0.6592 - val_loss: 0.4486 - val_root_mean_squared_error: 0.6698\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 539us/step - loss: 0.4126 - root_mean_squared_error: 0.6422 - val_loss: 0.4377 - val_root_mean_squared_error: 0.6616\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 551us/step - loss: 0.4100 - root_mean_squared_error: 0.6402 - val_loss: 0.4315 - val_root_mean_squared_error: 0.6569\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 524us/step - loss: 0.3930 - root_mean_squared_error: 0.6267 - val_loss: 0.4257 - val_root_mean_squared_error: 0.6524\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 538us/step - loss: 0.3947 - root_mean_squared_error: 0.6281 - val_loss: 0.4209 - val_root_mean_squared_error: 0.6487\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 534us/step - loss: 0.4207 - root_mean_squared_error: 0.6485 - val_loss: 0.4154 - val_root_mean_squared_error: 0.6445\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.3908 - root_mean_squared_error: 0.6251 - val_loss: 0.4114 - val_root_mean_squared_error: 0.6414\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 585us/step - loss: 0.3902 - root_mean_squared_error: 0.6246 - val_loss: 0.4077 - val_root_mean_squared_error: 0.6385\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 550us/step - loss: 0.3809 - root_mean_squared_error: 0.6170 - val_loss: 0.4035 - val_root_mean_squared_error: 0.6352\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 533us/step - loss: 0.3819 - root_mean_squared_error: 0.6178 - val_loss: 0.4026 - val_root_mean_squared_error: 0.6345\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 521us/step - loss: 0.3618 - root_mean_squared_error: 0.6013 - val_loss: 0.3991 - val_root_mean_squared_error: 0.6317\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 531us/step - loss: 0.3579 - root_mean_squared_error: 0.5978 - val_loss: 0.3926 - val_root_mean_squared_error: 0.6265\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 532us/step - loss: 0.3483 - root_mean_squared_error: 0.5901 - val_loss: 0.3886 - val_root_mean_squared_error: 0.6234\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 534us/step - loss: 0.3675 - root_mean_squared_error: 0.6061 - val_loss: 0.3858 - val_root_mean_squared_error: 0.6211\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.3615 - root_mean_squared_error: 0.6011 - val_loss: 0.3890 - val_root_mean_squared_error: 0.6237\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 534us/step - loss: 0.3482 - root_mean_squared_error: 0.5901 - val_loss: 0.3761 - val_root_mean_squared_error: 0.6133\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 522us/step - loss: 0.3655 - root_mean_squared_error: 0.6043 - val_loss: 0.3727 - val_root_mean_squared_error: 0.6105\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 532us/step - loss: 0.3395 - root_mean_squared_error: 0.5821 - val_loss: 0.3791 - val_root_mean_squared_error: 0.6157\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 539us/step - loss: 0.3378 - root_mean_squared_error: 0.5810 - val_loss: 0.3712 - val_root_mean_squared_error: 0.6093\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 527us/step - loss: 0.3388 - root_mean_squared_error: 0.5818 - val_loss: 0.3672 - val_root_mean_squared_error: 0.6059\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 527us/step - loss: 0.3368 - root_mean_squared_error: 0.5803 - val_loss: 0.3624 - val_root_mean_squared_error: 0.6020\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 531us/step - loss: 0.3413 - root_mean_squared_error: 0.5842 - val_loss: 0.3656 - val_root_mean_squared_error: 0.6046\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 526us/step - loss: 0.3228 - root_mean_squared_error: 0.5681 - val_loss: 0.3620 - val_root_mean_squared_error: 0.6017\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 526us/step - loss: 0.3233 - root_mean_squared_error: 0.5685 - val_loss: 0.3595 - val_root_mean_squared_error: 0.5996\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.3293 - root_mean_squared_error: 0.5738 - val_loss: 0.3593 - val_root_mean_squared_error: 0.5994\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 501us/step - loss: 0.3294 - root_mean_squared_error: 0.5738 - val_loss: 0.3531 - val_root_mean_squared_error: 0.5942\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 516us/step - loss: 0.3198 - root_mean_squared_error: 0.5654 - val_loss: 0.3566 - val_root_mean_squared_error: 0.5972\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 530us/step - loss: 0.3110 - root_mean_squared_error: 0.5576 - val_loss: 0.3568 - val_root_mean_squared_error: 0.5974\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 541us/step - loss: 0.3165 - root_mean_squared_error: 0.5623 - val_loss: 0.3468 - val_root_mean_squared_error: 0.5889\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 497us/step - loss: 0.3096 - root_mean_squared_error: 0.5562 - val_loss: 0.3673 - val_root_mean_squared_error: 0.6061\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 516us/step - loss: 0.3182 - root_mean_squared_error: 0.5640 - val_loss: 0.3467 - val_root_mean_squared_error: 0.5888\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.3509 - root_mean_squared_error: 0.5921 - val_loss: 0.3417 - val_root_mean_squared_error: 0.5846\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 490us/step - loss: 0.3176 - root_mean_squared_error: 0.5634 - val_loss: 0.3414 - val_root_mean_squared_error: 0.5843\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 565us/step - loss: 0.3237 - root_mean_squared_error: 0.5688 - val_loss: 0.3384 - val_root_mean_squared_error: 0.5817\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.3041 - root_mean_squared_error: 0.5512 - val_loss: 0.3381 - val_root_mean_squared_error: 0.5814\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 524us/step - loss: 0.3119 - root_mean_squared_error: 0.5582 - val_loss: 0.3377 - val_root_mean_squared_error: 0.5811\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 545us/step - loss: 0.3171 - root_mean_squared_error: 0.5631 - val_loss: 0.3380 - val_root_mean_squared_error: 0.5814\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 547us/step - loss: 0.3068 - root_mean_squared_error: 0.5537 - val_loss: 0.3302 - val_root_mean_squared_error: 0.5746\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 559us/step - loss: 0.3044 - root_mean_squared_error: 0.5516 - val_loss: 0.3325 - val_root_mean_squared_error: 0.5767\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 533us/step - loss: 0.3005 - root_mean_squared_error: 0.5481 - val_loss: 0.3385 - val_root_mean_squared_error: 0.5818\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 534us/step - loss: 0.3010 - root_mean_squared_error: 0.5485 - val_loss: 0.3338 - val_root_mean_squared_error: 0.5778\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 542us/step - loss: 0.2926 - root_mean_squared_error: 0.5409 - val_loss: 0.3311 - val_root_mean_squared_error: 0.5754\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 504us/step - loss: 0.2848 - root_mean_squared_error: 0.5333 - val_loss: 0.3284 - val_root_mean_squared_error: 0.5731\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 539us/step - loss: 0.2973 - root_mean_squared_error: 0.5452 - val_loss: 0.3255 - val_root_mean_squared_error: 0.5705\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 547us/step - loss: 0.3106 - root_mean_squared_error: 0.5572 - val_loss: 0.3348 - val_root_mean_squared_error: 0.5786\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 540us/step - loss: 0.3077 - root_mean_squared_error: 0.5544 - val_loss: 0.3230 - val_root_mean_squared_error: 0.5683\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 548us/step - loss: 0.2776 - root_mean_squared_error: 0.5267 - val_loss: 0.3432 - val_root_mean_squared_error: 0.5858\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 542us/step - loss: 0.2968 - root_mean_squared_error: 0.5445 - val_loss: 0.3319 - val_root_mean_squared_error: 0.5761\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 534us/step - loss: 0.3071 - root_mean_squared_error: 0.5536 - val_loss: 0.3205 - val_root_mean_squared_error: 0.5661\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 533us/step - loss: 0.3030 - root_mean_squared_error: 0.5503 - val_loss: 0.3196 - val_root_mean_squared_error: 0.5653\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 542us/step - loss: 0.2945 - root_mean_squared_error: 0.5425 - val_loss: 0.3225 - val_root_mean_squared_error: 0.5679\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.2893 - root_mean_squared_error: 0.5376 - val_loss: 0.3177 - val_root_mean_squared_error: 0.5637\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 543us/step - loss: 0.2806 - root_mean_squared_error: 0.5296 - val_loss: 0.3215 - val_root_mean_squared_error: 0.5670\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 551us/step - loss: 0.2919 - root_mean_squared_error: 0.5401 - val_loss: 0.3164 - val_root_mean_squared_error: 0.5625\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 540us/step - loss: 0.2776 - root_mean_squared_error: 0.5267 - val_loss: 0.3461 - val_root_mean_squared_error: 0.5883\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 535us/step - loss: 0.2941 - root_mean_squared_error: 0.5422 - val_loss: 0.3242 - val_root_mean_squared_error: 0.5694\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 565us/step - loss: 0.2915 - root_mean_squared_error: 0.5398 - val_loss: 0.3298 - val_root_mean_squared_error: 0.5743\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 543us/step - loss: 0.2706 - root_mean_squared_error: 0.5196 - val_loss: 0.3259 - val_root_mean_squared_error: 0.5709\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 544us/step - loss: 0.2785 - root_mean_squared_error: 0.5276 - val_loss: 0.3129 - val_root_mean_squared_error: 0.5594\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 530us/step - loss: 0.2856 - root_mean_squared_error: 0.5342 - val_loss: 0.3120 - val_root_mean_squared_error: 0.5586\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 541us/step - loss: 0.2772 - root_mean_squared_error: 0.5261 - val_loss: 0.3121 - val_root_mean_squared_error: 0.5587\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 534us/step - loss: 0.2696 - root_mean_squared_error: 0.5189 - val_loss: 0.3094 - val_root_mean_squared_error: 0.5562\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 532us/step - loss: 0.3077 - root_mean_squared_error: 0.5543 - val_loss: 0.3212 - val_root_mean_squared_error: 0.5667\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 541us/step - loss: 0.2723 - root_mean_squared_error: 0.5215 - val_loss: 0.3114 - val_root_mean_squared_error: 0.5581\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 547us/step - loss: 0.2715 - root_mean_squared_error: 0.5209 - val_loss: 0.3106 - val_root_mean_squared_error: 0.5573\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 542us/step - loss: 0.2843 - root_mean_squared_error: 0.5331 - val_loss: 0.3154 - val_root_mean_squared_error: 0.5616\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 543us/step - loss: 0.2923 - root_mean_squared_error: 0.5404 - val_loss: 0.3110 - val_root_mean_squared_error: 0.5577\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 537us/step - loss: 0.2737 - root_mean_squared_error: 0.5228 - val_loss: 0.3082 - val_root_mean_squared_error: 0.5552\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 544us/step - loss: 0.2734 - root_mean_squared_error: 0.5222 - val_loss: 0.3103 - val_root_mean_squared_error: 0.5571\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 551us/step - loss: 0.2761 - root_mean_squared_error: 0.5253 - val_loss: 0.3134 - val_root_mean_squared_error: 0.5598\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 542us/step - loss: 0.2744 - root_mean_squared_error: 0.5237 - val_loss: 0.3102 - val_root_mean_squared_error: 0.5570\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 533us/step - loss: 0.2613 - root_mean_squared_error: 0.5108 - val_loss: 0.3073 - val_root_mean_squared_error: 0.5543\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 540us/step - loss: 0.2668 - root_mean_squared_error: 0.5163 - val_loss: 0.3079 - val_root_mean_squared_error: 0.5549\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 524us/step - loss: 0.2838 - root_mean_squared_error: 0.5325 - val_loss: 0.3106 - val_root_mean_squared_error: 0.5573\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 537us/step - loss: 0.2758 - root_mean_squared_error: 0.5250 - val_loss: 0.3042 - val_root_mean_squared_error: 0.5515\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 524us/step - loss: 0.2669 - root_mean_squared_error: 0.5166 - val_loss: 0.3312 - val_root_mean_squared_error: 0.5755\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 524us/step - loss: 0.2606 - root_mean_squared_error: 0.5103 - val_loss: 0.3325 - val_root_mean_squared_error: 0.5767\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 532us/step - loss: 0.2762 - root_mean_squared_error: 0.5255 - val_loss: 0.3093 - val_root_mean_squared_error: 0.5562\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 550us/step - loss: 0.2698 - root_mean_squared_error: 0.5193 - val_loss: 0.3059 - val_root_mean_squared_error: 0.5531\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 550us/step - loss: 0.2664 - root_mean_squared_error: 0.5160 - val_loss: 0.3068 - val_root_mean_squared_error: 0.5539\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 542us/step - loss: 0.2737 - root_mean_squared_error: 0.5231 - val_loss: 0.3004 - val_root_mean_squared_error: 0.5481\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 534us/step - loss: 0.2660 - root_mean_squared_error: 0.5157 - val_loss: 0.3099 - val_root_mean_squared_error: 0.5567\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 522us/step - loss: 0.2718 - root_mean_squared_error: 0.5211 - val_loss: 0.3100 - val_root_mean_squared_error: 0.5568\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 567us/step - loss: 0.2611 - root_mean_squared_error: 0.5108 - val_loss: 0.3126 - val_root_mean_squared_error: 0.5591\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 556us/step - loss: 0.2895 - root_mean_squared_error: 0.5378 - val_loss: 0.3122 - val_root_mean_squared_error: 0.5588\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 523us/step - loss: 0.2652 - root_mean_squared_error: 0.5148 - val_loss: 0.2992 - val_root_mean_squared_error: 0.5470\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 546us/step - loss: 0.2681 - root_mean_squared_error: 0.5176 - val_loss: 0.3043 - val_root_mean_squared_error: 0.5516\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 527us/step - loss: 0.2614 - root_mean_squared_error: 0.5111 - val_loss: 0.3162 - val_root_mean_squared_error: 0.5623\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 543us/step - loss: 0.2604 - root_mean_squared_error: 0.5102 - val_loss: 0.3135 - val_root_mean_squared_error: 0.5599\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 539us/step - loss: 0.2682 - root_mean_squared_error: 0.5178 - val_loss: 0.3129 - val_root_mean_squared_error: 0.5594\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 546us/step - loss: 0.2777 - root_mean_squared_error: 0.5268 - val_loss: 0.3033 - val_root_mean_squared_error: 0.5507\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 557us/step - loss: 0.2644 - root_mean_squared_error: 0.5140 - val_loss: 0.3053 - val_root_mean_squared_error: 0.5525\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 546us/step - loss: 0.2561 - root_mean_squared_error: 0.5056 - val_loss: 0.3082 - val_root_mean_squared_error: 0.5552\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 535us/step - loss: 0.2579 - root_mean_squared_error: 0.5077 - val_loss: 0.3097 - val_root_mean_squared_error: 0.5565\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 543us/step - loss: 0.2567 - root_mean_squared_error: 0.5065 - val_loss: 0.3064 - val_root_mean_squared_error: 0.5535\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 498us/step - loss: 0.2638 - root_mean_squared_error: 0.5134 - val_loss: 0.3037 - val_root_mean_squared_error: 0.5511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21fc154e3d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(\n",
    "    build_model,\n",
    "    learning_rate=rnd_search_cv.best_params_['learning_rate'],\n",
    "    n_hidden=rnd_search_cv.best_params_['n_hidden'],\n",
    "    n_neurons=rnd_search_cv.best_params_['n_neurons']\n",
    ")\n",
    "keras_reg.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10)]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
